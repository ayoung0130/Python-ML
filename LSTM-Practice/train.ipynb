{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "\n",
    "# GPU 선택 -> '1': 두 번째\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# GPU 메모리의 동적 할당 허용\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(528, 30, 298)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    '부러지다',\n",
    "    '기절',\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_부러지다_1711895632.npy'),\n",
    "    np.load('dataset/seq_기절_1711895733.npy'),\n",
    "], axis=0)\n",
    "\n",
    "data.shape\n",
    "# (데이터의 개수, 프레임 사이즈, 한 프레임당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(528, 30, 298)\n",
      "(528,)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스의 마지막 열 제외한 모든 열 가져와 할당\n",
    "# 첫 번째 행의 마지막 열은 라벨 값\n",
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(np.unique(labels))    # 레이블 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(528, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 원-핫 인코딩으로 변환\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 30, 297) (369, 2)\n",
      "(159, 30, 297) (159, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)  # 입력 데이터\n",
    "y_data = y_data.astype(np.float32)  # 레이블\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                92672     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,818\n",
      "Trainable params: 94,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "# compile(최적화 알고리즘, 레이블 클래스 2개 이상일 때 사용하는 손실 함수, 모델평가지표)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 5.0957 - acc: 0.5208 \n",
      "Epoch 1: val_acc improved from -inf to 0.57862, saving model to models\\model.h5\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 4.1292 - acc: 0.5230 - val_loss: 0.6922 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 2/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6925 - acc: 0.5451\n",
      "Epoch 2: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6925 - acc: 0.5447 - val_loss: 0.6915 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 3/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6920 - acc: 0.5521\n",
      "Epoch 3: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6921 - acc: 0.5447 - val_loss: 0.6908 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 4/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6921 - acc: 0.5347\n",
      "Epoch 4: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6917 - acc: 0.5447 - val_loss: 0.6902 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 5/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6925 - acc: 0.5208\n",
      "Epoch 5: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6915 - acc: 0.5447 - val_loss: 0.6899 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6915 - acc: 0.5426\n",
      "Epoch 6: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6913 - acc: 0.5447 - val_loss: 0.6893 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6910 - acc: 0.5455\n",
      "Epoch 7: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6910 - acc: 0.5447 - val_loss: 0.6889 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6908 - acc: 0.5455\n",
      "Epoch 8: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6908 - acc: 0.5447 - val_loss: 0.6885 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 9/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6921 - acc: 0.5243\n",
      "Epoch 9: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6906 - acc: 0.5447 - val_loss: 0.6881 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 10/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6904 - acc: 0.5451\n",
      "Epoch 10: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6905 - acc: 0.5447 - val_loss: 0.6877 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6903 - acc: 0.5455\n",
      "Epoch 11: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6903 - acc: 0.5447 - val_loss: 0.6873 - val_acc: 0.5786 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6902 - acc: 0.5447\n",
      "Epoch 12: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6902 - acc: 0.5447 - val_loss: 0.6871 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6901 - acc: 0.5447\n",
      "Epoch 13: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6901 - acc: 0.5447 - val_loss: 0.6869 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6893 - acc: 0.5531\n",
      "Epoch 14: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6901 - acc: 0.5447 - val_loss: 0.6867 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.5447\n",
      "Epoch 15: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6900 - acc: 0.5447 - val_loss: 0.6866 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6894 - acc: 0.5500\n",
      "Epoch 16: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6899 - acc: 0.5447 - val_loss: 0.6865 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6903 - acc: 0.5406\n",
      "Epoch 17: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6899 - acc: 0.5447 - val_loss: 0.6864 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6887 - acc: 0.5562\n",
      "Epoch 18: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6899 - acc: 0.5447 - val_loss: 0.6862 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6899 - acc: 0.5437\n",
      "Epoch 19: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6898 - acc: 0.5447 - val_loss: 0.6861 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6903 - acc: 0.5398\n",
      "Epoch 20: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6898 - acc: 0.5447 - val_loss: 0.6860 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6888 - acc: 0.5531\n",
      "Epoch 21: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6897 - acc: 0.5447 - val_loss: 0.6858 - val_acc: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6916 - acc: 0.5281\n",
      "Epoch 22: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6897 - acc: 0.5447 - val_loss: 0.6858 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6899 - acc: 0.5426\n",
      "Epoch 23: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6897 - acc: 0.5447 - val_loss: 0.6857 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6909 - acc: 0.5344\n",
      "Epoch 24: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6896 - acc: 0.5447 - val_loss: 0.6857 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6908 - acc: 0.5347\n",
      "Epoch 25: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6896 - acc: 0.5447 - val_loss: 0.6856 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6908 - acc: 0.5344\n",
      "Epoch 26: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6896 - acc: 0.5447 - val_loss: 0.6856 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6919 - acc: 0.5250\n",
      "Epoch 27: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6896 - acc: 0.5447 - val_loss: 0.6855 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6874 - acc: 0.5625\n",
      "Epoch 28: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6896 - acc: 0.5447 - val_loss: 0.6854 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6881 - acc: 0.5562\n",
      "Epoch 29: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6896 - acc: 0.5447 - val_loss: 0.6854 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6908 - acc: 0.5344\n",
      "Epoch 30: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6853 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6887 - acc: 0.5511\n",
      "Epoch 31: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6853 - val_acc: 0.5786 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6894 - acc: 0.5455\n",
      "Epoch 32: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6853 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6900 - acc: 0.5406\n",
      "Epoch 33: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6853 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6891 - acc: 0.5483\n",
      "Epoch 34: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6852 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6894 - acc: 0.5455\n",
      "Epoch 35: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6852 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6908 - acc: 0.5344\n",
      "Epoch 36: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6852 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5437\n",
      "Epoch 37: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6852 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5437\n",
      "Epoch 38: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6852 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6925 - acc: 0.5208\n",
      "Epoch 39: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6851 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5437\n",
      "Epoch 40: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6851 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.5447\n",
      "Epoch 41: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6851 - val_acc: 0.5786 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6888 - acc: 0.5500\n",
      "Epoch 42: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6851 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6924 - acc: 0.5219\n",
      "Epoch 43: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6851 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6892 - acc: 0.5469\n",
      "Epoch 44: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6895 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6879 - acc: 0.5562\n",
      "Epoch 45: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.6903 - acc: 0.5382\n",
      "Epoch 46: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 47: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6879 - acc: 0.5562\n",
      "Epoch 48: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6892 - acc: 0.5469\n",
      "Epoch 49: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6904 - acc: 0.5375\n",
      "Epoch 50: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 51: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6920 - acc: 0.5250\n",
      "Epoch 52: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6887 - acc: 0.5500\n",
      "Epoch 53: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6904 - acc: 0.5375\n",
      "Epoch 54: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5437\n",
      "Epoch 55: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5437\n",
      "Epoch 56: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6850 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6883 - acc: 0.5531\n",
      "Epoch 57: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6891 - acc: 0.5469\n",
      "Epoch 58: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 59: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6875 - acc: 0.5594\n",
      "Epoch 60: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 61/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6900 - acc: 0.5406\n",
      "Epoch 61: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.1250e-05\n",
      "Epoch 62/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6908 - acc: 0.5344\n",
      "Epoch 62: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 63: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6879 - acc: 0.5562\n",
      "Epoch 64: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6895 - acc: 0.5437\n",
      "Epoch 65: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 66/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6887 - acc: 0.5500\n",
      "Epoch 66: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 67/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6920 - acc: 0.5250\n",
      "Epoch 67: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 68/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6900 - acc: 0.5406\n",
      "Epoch 68: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 69: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 70/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6883 - acc: 0.5531\n",
      "Epoch 70: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 71/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6886 - acc: 0.5511\n",
      "Epoch 71: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.5625e-05\n",
      "Epoch 72/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6889 - acc: 0.5483\n",
      "Epoch 72: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 73: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 74: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 75: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 76: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 77/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6904 - acc: 0.5369\n",
      "Epoch 77: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 78: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 79/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6886 - acc: 0.5511\n",
      "Epoch 79: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 80/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6916 - acc: 0.5284\n",
      "Epoch 80: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 81/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6866 - acc: 0.5656\n",
      "Epoch 81: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 7.8125e-06\n",
      "Epoch 82/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6891 - acc: 0.5469\n",
      "Epoch 82: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 83: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 84/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6900 - acc: 0.5406\n",
      "Epoch 84: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 85: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 86/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6900 - acc: 0.5406\n",
      "Epoch 86: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 87/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6904 - acc: 0.5375\n",
      "Epoch 87: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 88: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 89/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6920 - acc: 0.5250\n",
      "Epoch 89: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 90: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 91: val_acc did not improve from 0.57862\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 3.9063e-06\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 92: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 93/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6891 - acc: 0.5469\n",
      "Epoch 93: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 94: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 95/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6904 - acc: 0.5375\n",
      "Epoch 95: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 96/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6908 - acc: 0.5341\n",
      "Epoch 96: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 97/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.6901 - acc: 0.5398\n",
      "Epoch 97: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 98: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 99/100\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 0.6920 - acc: 0.5250\n",
      "Epoch 99: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6894 - acc: 0.5447\n",
      "Epoch 100: val_acc did not improve from 0.57862\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6894 - acc: 0.5447 - val_loss: 0.6849 - val_acc: 0.5786 - lr: 1.9531e-06\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        # save_best_only -> 모델 정확도가 이전보다 향상된 경우에만 모델 저장\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        # 정확도 개선이 없을시 학습률(factor) 0.5배로 감소, 50 에포크 동안 개선 없을 경우 학습률 감소\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[92,  0],\n",
       "        [67,  0]],\n",
       "\n",
       "       [[ 0, 67],\n",
       "        [ 0, 92]]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# 다중 레이블 혼동 행렬로 모델 평가\n",
    "# [[True Negative, False Positive],\n",
    "# [False Negative, True Positive]]\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
