{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "\n",
    "# GPU 선택 -> '1': 두 번째\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# GPU 메모리의 동적 할당 허용\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 5, 298)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    '가렵다',\n",
    "    '부러지다',\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_가렵다_1711887585.npy'),\n",
    "    np.load('dataset/seq_가렵다_1711887588.npy'),\n",
    "    np.load('dataset/seq_가렵다_1711887595.npy'),\n",
    "    np.load('dataset/seq_부러지다_1711887647.npy'),\n",
    "    np.load('dataset/seq_부러지다_1711887651.npy'),\n",
    "    np.load('dataset/seq_부러지다_1711887656.npy'),\n",
    "], axis=0)\n",
    "\n",
    "data.shape\n",
    "# (데이터의 개수, 프레임 사이즈, 한 프레임당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534, 5, 298)\n",
      "(534,)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스의 마지막 열 제외한 모든 열 가져와 할당\n",
    "# 첫 번째 행의 마지막 열은 라벨 값\n",
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(data.shape)\n",
    "# print(data[0,1,:])\n",
    "print(labels.shape)\n",
    "print(np.unique(labels))    # 레이블 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 원-핫 인코딩으로 변환\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 5, 297) (480, 2)\n",
      "(54, 5, 297) (54, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)  # 입력 데이터\n",
    "y_data = y_data.astype(np.float32)  # 레이블\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                92672     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,818\n",
      "Trainable params: 94,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "# compile(최적화 알고리즘, 레이블 클래스 2개 이상일 때 사용하는 손실 함수, 모델평가지표)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 1.1510 - acc: 0.4760 \n",
      "Epoch 1: val_acc improved from -inf to 0.42593, saving model to models\\model.h5\n",
      "15/15 [==============================] - 2s 36ms/step - loss: 1.0900 - acc: 0.4729 - val_loss: 0.6932 - val_acc: 0.4259 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6929 - acc: 0.5344\n",
      "Epoch 2: val_acc improved from 0.42593 to 0.57407, saving model to models\\model.h5\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6932 - acc: 0.5104 - val_loss: 0.6920 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6927 - acc: 0.5312\n",
      "Epoch 3: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6927 - acc: 0.5271 - val_loss: 0.6915 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6923 - acc: 0.5369\n",
      "Epoch 4: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6926 - acc: 0.5271 - val_loss: 0.6911 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 5/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 5: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6924 - acc: 0.5271 - val_loss: 0.6909 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6923 - acc: 0.5271\n",
      "Epoch 6: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6923 - acc: 0.5271 - val_loss: 0.6904 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6926 - acc: 0.5182\n",
      "Epoch 7: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6922 - acc: 0.5271 - val_loss: 0.6901 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6908 - acc: 0.5547\n",
      "Epoch 8: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6922 - acc: 0.5271 - val_loss: 0.6895 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6924 - acc: 0.5208\n",
      "Epoch 9: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6920 - acc: 0.5271 - val_loss: 0.6894 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6934 - acc: 0.5026\n",
      "Epoch 10: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6920 - acc: 0.5271 - val_loss: 0.6892 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6916 - acc: 0.5335\n",
      "Epoch 11: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6920 - acc: 0.5271 - val_loss: 0.6888 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6932 - acc: 0.5085\n",
      "Epoch 12: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6919 - acc: 0.5271 - val_loss: 0.6888 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6932 - acc: 0.5078\n",
      "Epoch 13: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6919 - acc: 0.5271 - val_loss: 0.6886 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6919 - acc: 0.5260\n",
      "Epoch 14: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6883 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6913 - acc: 0.5341\n",
      "Epoch 15: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6881 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 16/200\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.6909 - acc: 0.5391\n",
      "Epoch 16: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6880 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6927 - acc: 0.5156\n",
      "Epoch 17: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6879 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6920 - acc: 0.5246\n",
      "Epoch 18: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6877 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6936 - acc: 0.5052\n",
      "Epoch 19: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6878 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6924 - acc: 0.5192\n",
      "Epoch 20: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6876 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6916 - acc: 0.5284\n",
      "Epoch 21: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6875 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6929 - acc: 0.5142\n",
      "Epoch 22: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6874 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 23/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6897 - acc: 0.5486\n",
      "Epoch 23: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6872 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6921 - acc: 0.5234\n",
      "Epoch 24: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6873 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 25/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6846 - acc: 0.6007\n",
      "Epoch 25: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6919 - acc: 0.5271 - val_loss: 0.6869 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6897 - acc: 0.5469\n",
      "Epoch 26: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6870 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 27/200\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.6909 - acc: 0.5352\n",
      "Epoch 27: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6871 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6933 - acc: 0.5104\n",
      "Epoch 28: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6872 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 29/200\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.6940 - acc: 0.5039\n",
      "Epoch 29: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6871 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6962 - acc: 0.4812\n",
      "Epoch 30: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6871 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6910 - acc: 0.5341\n",
      "Epoch 31: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6869 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6928 - acc: 0.5170\n",
      "Epoch 32: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6869 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6916 - acc: 0.5286\n",
      "Epoch 33: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6868 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6948 - acc: 0.4974\n",
      "Epoch 34: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6870 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6906 - acc: 0.5375\n",
      "Epoch 35: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6869 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6924 - acc: 0.5199\n",
      "Epoch 36: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6869 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6888 - acc: 0.5547\n",
      "Epoch 37: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6935 - acc: 0.5114\n",
      "Epoch 38: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6869 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 39/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6902 - acc: 0.5417\n",
      "Epoch 39: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6868 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6921 - acc: 0.5234\n",
      "Epoch 40: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6868 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6907 - acc: 0.5365\n",
      "Epoch 41: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6908 - acc: 0.5357\n",
      "Epoch 42: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6929 - acc: 0.5156\n",
      "Epoch 43: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 44/200\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.6892 - acc: 0.5508\n",
      "Epoch 44: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6926 - acc: 0.5192\n",
      "Epoch 45: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5271 - val_loss: 0.6868 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6908 - acc: 0.5361\n",
      "Epoch 46: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6895 - acc: 0.5469\n",
      "Epoch 47: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6924 - acc: 0.5208\n",
      "Epoch 48: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6913 - acc: 0.5312\n",
      "Epoch 49: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6925 - acc: 0.5201\n",
      "Epoch 50: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6925 - acc: 0.5192\n",
      "Epoch 51: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6910 - acc: 0.5335\n",
      "Epoch 52: val_acc did not improve from 0.57407\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 53: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6910 - acc: 0.5335\n",
      "Epoch 54: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6908 - acc: 0.5357\n",
      "Epoch 55: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6900 - acc: 0.5424\n",
      "Epoch 56: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 57: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 58: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6915 - acc: 0.5288\n",
      "Epoch 59: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6913 - acc: 0.5312\n",
      "Epoch 60: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6926 - acc: 0.5192\n",
      "Epoch 61: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6910 - acc: 0.5337\n",
      "Epoch 62: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6910 - acc: 0.5337\n",
      "Epoch 63: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6920 - acc: 0.5243\n",
      "Epoch 64: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6910 - acc: 0.5337\n",
      "Epoch 65: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 66: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 67: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6894 - acc: 0.5483\n",
      "Epoch 68: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6915 - acc: 0.5288\n",
      "Epoch 69: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6907 - acc: 0.5361\n",
      "Epoch 70: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6918 - acc: 0.5264\n",
      "Epoch 71: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6915 - acc: 0.5290\n",
      "Epoch 72: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5240\n",
      "Epoch 73: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6927 - acc: 0.5179\n",
      "Epoch 74: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6920 - acc: 0.5246\n",
      "Epoch 75: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6923 - acc: 0.5216\n",
      "Epoch 76: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6931 - acc: 0.5144\n",
      "Epoch 77: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 78: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6923 - acc: 0.5219\n",
      "Epoch 79: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6910 - acc: 0.5337\n",
      "Epoch 80: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6917 - acc: 0.5268\n",
      "Epoch 81: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6910 - acc: 0.5335\n",
      "Epoch 82: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6920 - acc: 0.5246\n",
      "Epoch 83: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5240\n",
      "Epoch 84: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 85: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6904 - acc: 0.5391\n",
      "Epoch 86: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6933 - acc: 0.5120\n",
      "Epoch 87: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6937 - acc: 0.5078\n",
      "Epoch 88: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6918 - acc: 0.5264\n",
      "Epoch 89: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 90: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6916 - acc: 0.5284\n",
      "Epoch 91: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6922 - acc: 0.5227\n",
      "Epoch 92: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 93: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6932 - acc: 0.5130\n",
      "Epoch 94: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6867 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6930 - acc: 0.5144\n",
      "Epoch 95: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6910 - acc: 0.5337\n",
      "Epoch 96: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6910 - acc: 0.5339\n",
      "Epoch 97: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6904 - acc: 0.5385\n",
      "Epoch 98: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5240\n",
      "Epoch 99: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6929 - acc: 0.5156\n",
      "Epoch 100: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6910 - acc: 0.5339\n",
      "Epoch 101: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6923 - acc: 0.5216\n",
      "Epoch 102: val_acc did not improve from 0.57407\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 103: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 104/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6923 - acc: 0.5216\n",
      "Epoch 104: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 105/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6932 - acc: 0.5130\n",
      "Epoch 105: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6921 - acc: 0.5234\n",
      "Epoch 106: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6920 - acc: 0.5246\n",
      "Epoch 107: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 108: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6905 - acc: 0.5382\n",
      "Epoch 109: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5240\n",
      "Epoch 110: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6918 - acc: 0.5264\n",
      "Epoch 111: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 112: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6907 - acc: 0.5361\n",
      "Epoch 113: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6924 - acc: 0.5208\n",
      "Epoch 114: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6907 - acc: 0.5357\n",
      "Epoch 115: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6886 - acc: 0.5556\n",
      "Epoch 116: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 117: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6915 - acc: 0.5290\n",
      "Epoch 118: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6905 - acc: 0.5385\n",
      "Epoch 119: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6910 - acc: 0.5337\n",
      "Epoch 120: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6921 - acc: 0.5234\n",
      "Epoch 121: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5240\n",
      "Epoch 122: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6917 - acc: 0.5268\n",
      "Epoch 123: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 124: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 125: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6906 - acc: 0.5369\n",
      "Epoch 126: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6915 - acc: 0.5288\n",
      "Epoch 127: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6931 - acc: 0.5144\n",
      "Epoch 128: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6925 - acc: 0.5192\n",
      "Epoch 129: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6926 - acc: 0.5182\n",
      "Epoch 130: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5240\n",
      "Epoch 131: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.6908 - acc: 0.5352\n",
      "Epoch 132: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6925 - acc: 0.5192\n",
      "Epoch 133: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6899 - acc: 0.5433\n",
      "Epoch 134: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6923 - acc: 0.5216\n",
      "Epoch 135: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6928 - acc: 0.5168\n",
      "Epoch 136: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6952 - acc: 0.4948\n",
      "Epoch 137: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6924 - acc: 0.5208\n",
      "Epoch 138: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6901 - acc: 0.5417\n",
      "Epoch 139: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6931 - acc: 0.5142\n",
      "Epoch 140: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6886 - acc: 0.5556\n",
      "Epoch 141: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6901 - acc: 0.5417\n",
      "Epoch 142: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 143: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      " 8/15 [===============>..............] - ETA: 0s - loss: 0.6925 - acc: 0.5195\n",
      "Epoch 144: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6929 - acc: 0.5156\n",
      "Epoch 145: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6937 - acc: 0.5085\n",
      "Epoch 146: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6940 - acc: 0.5063\n",
      "Epoch 147: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6918 - acc: 0.5256\n",
      "Epoch 148: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6920 - acc: 0.5243\n",
      "Epoch 149: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6892 - acc: 0.5500\n",
      "Epoch 150: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6865 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6929 - acc: 0.5156\n",
      "Epoch 151: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6916 - acc: 0.5281\n",
      "Epoch 152: val_acc did not improve from 0.57407\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6919 - acc: 0.5250\n",
      "Epoch 153: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 154/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6902 - acc: 0.5406\n",
      "Epoch 154: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 155/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6935 - acc: 0.5104\n",
      "Epoch 155: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 156/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6919 - acc: 0.5250\n",
      "Epoch 156: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 157/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6888 - acc: 0.5531\n",
      "Epoch 157: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 158/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6901 - acc: 0.5417\n",
      "Epoch 158: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.5271\n",
      "Epoch 159: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 160/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6933 - acc: 0.5120\n",
      "Epoch 160: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.5271\n",
      "Epoch 161: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 162/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6955 - acc: 0.4922\n",
      "Epoch 162: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 163/200\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 163: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 164/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6871 - acc: 0.5694\n",
      "Epoch 164: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 165/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6927 - acc: 0.5174\n",
      "Epoch 165: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 166: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6927 - acc: 0.5174\n",
      "Epoch 167: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6935 - acc: 0.5104\n",
      "Epoch 168: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6893 - acc: 0.5495\n",
      "Epoch 169: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.5271\n",
      "Epoch 170: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6935 - acc: 0.5104\n",
      "Epoch 171: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.5271\n",
      "Epoch 172: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 0.6915 - acc: 0.5290\n",
      "Epoch 173: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.5271\n",
      "Epoch 174: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6901 - acc: 0.5417\n",
      "Epoch 175: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "12/15 [=======================>......] - ETA: 0s - loss: 0.6895 - acc: 0.5469\n",
      "Epoch 176: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6931 - acc: 0.5139\n",
      "Epoch 177: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6965 - acc: 0.4826\n",
      "Epoch 178: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      " 7/15 [=============>................] - ETA: 0s - loss: 0.6922 - acc: 0.5223\n",
      "Epoch 179: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 180: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6893 - acc: 0.5486\n",
      "Epoch 181: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6916 - acc: 0.5281\n",
      "Epoch 182: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6926 - acc: 0.5188\n",
      "Epoch 183: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6919 - acc: 0.5250\n",
      "Epoch 184: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6926 - acc: 0.5188\n",
      "Epoch 185: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6931 - acc: 0.5142\n",
      "Epoch 186: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6909 - acc: 0.5344\n",
      "Epoch 187: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6905 - acc: 0.5375\n",
      "Epoch 188: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6925 - acc: 0.5199\n",
      "Epoch 189: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6897 - acc: 0.5451\n",
      "Epoch 190: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6925 - acc: 0.5199\n",
      "Epoch 191: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6903 - acc: 0.5398\n",
      "Epoch 192: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6902 - acc: 0.5406\n",
      "Epoch 193: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6899 - acc: 0.5437\n",
      "Epoch 194: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6926 - acc: 0.5188\n",
      "Epoch 195: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6929 - acc: 0.5156\n",
      "Epoch 196: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "11/15 [=====================>........] - ETA: 0s - loss: 0.6931 - acc: 0.5142\n",
      "Epoch 197: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      " 9/15 [=================>............] - ETA: 0s - loss: 0.6912 - acc: 0.5312\n",
      "Epoch 198: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.5271\n",
      "Epoch 199: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.6916 - acc: 0.5281\n",
      "Epoch 200: val_acc did not improve from 0.57407\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.5271 - val_loss: 0.6866 - val_acc: 0.5741 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        # save_best_only -> 모델 정확도가 이전보다 향상된 경우에만 모델 저장\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        # 정확도 개선이 없을시 학습률(factor) 0.5배로 감소, 50 에포크 동안 개선 없을 경우 학습률 감소\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0, 23],\n",
       "        [ 0, 31]],\n",
       "\n",
       "       [[31,  0],\n",
       "        [23,  0]]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# 다중 레이블 혼동 행렬로 모델 평가\n",
    "# [[True Negative, False Positive],\n",
    "# [False Negative, True Positive]]\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
