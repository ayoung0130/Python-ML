{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "\n",
    "# GPU 선택 -> '1': 두 번째\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# GPU 메모리의 동적 할당 허용\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 5, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'come',\n",
    "    'away',\n",
    "    'spin'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_come_1709861022_1.npy'),\n",
    "    np.load('dataset/seq_come_1709861022_2.npy'),\n",
    "    np.load('dataset/seq_away_1709861022_1.npy'),\n",
    "    np.load('dataset/seq_away_1709861022_2.npy'),\n",
    "    np.load('dataset/seq_spin_1709861022_1.npy'),\n",
    "    np.load('dataset/seq_spin_1709861022_2.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape\n",
    "# (데이터의 개수, 윈도우의 사이즈, 한 윈도우당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 5, 99)\n",
      "(164,)\n"
     ]
    }
   ],
   "source": [
    "# 시퀀스의 마지막 열 제외한 모든 열 가져와 할당\n",
    "# 마지막 열은 라벨 값\n",
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 원-핫 인코딩으로 변환\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 5, 99) (147, 3)\n",
      "(17, 5, 99) (17, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                41984     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,163\n",
      "Trainable params: 44,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "# compile(옵티마이저, 손실함수, 모델평가지표)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/5 [=====>........................] - ETA: 5s - loss: 13.1517 - acc: 0.0000e+00\n",
      "Epoch 1: val_acc improved from -inf to 0.52941, saving model to models\\model.h5\n",
      "5/5 [==============================] - 2s 116ms/step - loss: 8.4197 - acc: 0.2517 - val_loss: 1.3305 - val_acc: 0.5294 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9871 - acc: 0.5625\n",
      "Epoch 2: val_acc improved from 0.52941 to 0.94118, saving model to models\\model.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7033 - acc: 0.7959 - val_loss: 0.1491 - val_acc: 0.9412 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1366 - acc: 0.9688\n",
      "Epoch 3: val_acc improved from 0.94118 to 1.00000, saving model to models\\model.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0538 - acc: 0.9796 - val_loss: 0.0100 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8575e-04 - acc: 1.0000\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1512e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2884e-05 - acc: 1.0000\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9164e-05 - acc: 1.0000 - val_loss: 4.9542e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5757e-05 - acc: 1.0000\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3124e-04 - acc: 1.0000 - val_loss: 2.1527e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7641e-04 - acc: 1.0000\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2400e-04 - acc: 1.0000 - val_loss: 1.3855e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0848e-06 - acc: 1.0000\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2948e-05 - acc: 1.0000 - val_loss: 1.0426e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8580e-06 - acc: 1.0000\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7467e-05 - acc: 1.0000 - val_loss: 8.9161e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0994e-06 - acc: 1.0000\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8215e-06 - acc: 1.0000 - val_loss: 7.9847e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7594e-06 - acc: 1.0000\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2518e-06 - acc: 1.0000 - val_loss: 7.3635e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7289e-06 - acc: 1.0000\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3444e-06 - acc: 1.0000 - val_loss: 6.9348e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8056e-07 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.8425e-06 - acc: 1.0000 - val_loss: 6.6049e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5907e-06 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.6017e-06 - acc: 1.0000 - val_loss: 6.3331e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0079e-06 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3868e-06 - acc: 1.0000 - val_loss: 6.1047e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6118e-06 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2173e-06 - acc: 1.0000 - val_loss: 5.9113e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5857e-06 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.0746e-06 - acc: 1.0000 - val_loss: 5.6921e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6054e-07 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.8890e-06 - acc: 1.0000 - val_loss: 5.5127e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7546e-06 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7633e-06 - acc: 1.0000 - val_loss: 5.3179e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1283e-05 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6684e-06 - acc: 1.0000 - val_loss: 5.1253e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3418e-06 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5363e-06 - acc: 1.0000 - val_loss: 4.9571e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0654e-06 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3919e-06 - acc: 1.0000 - val_loss: 4.8289e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4789e-06 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3190e-06 - acc: 1.0000 - val_loss: 4.6866e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7497e-06 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2281e-06 - acc: 1.0000 - val_loss: 4.5500e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2405e-06 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1081e-06 - acc: 1.0000 - val_loss: 4.4435e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4703e-07 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0368e-06 - acc: 1.0000 - val_loss: 4.3202e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5390e-07 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9525e-06 - acc: 1.0000 - val_loss: 4.2010e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0750e-06 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8495e-06 - acc: 1.0000 - val_loss: 4.1022e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1586e-06 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7757e-06 - acc: 1.0000 - val_loss: 3.9740e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1250e-06 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.6979e-06 - acc: 1.0000 - val_loss: 3.8528e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1995e-06 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.6241e-06 - acc: 1.0000 - val_loss: 3.7371e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0824e-06 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.5341e-06 - acc: 1.0000 - val_loss: 3.6425e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2815e-06 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4716e-06 - acc: 1.0000 - val_loss: 3.5423e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8254e-07 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3914e-06 - acc: 1.0000 - val_loss: 3.4568e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4995e-07 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.3508e-06 - acc: 1.0000 - val_loss: 3.3383e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9779e-07 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2608e-06 - acc: 1.0000 - val_loss: 3.2395e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1153e-07 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2008e-06 - acc: 1.0000 - val_loss: 3.1456e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5204e-06 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1497e-06 - acc: 1.0000 - val_loss: 3.0461e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5114e-06 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0849e-06 - acc: 1.0000 - val_loss: 2.9550e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2585e-07 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9957e-06 - acc: 1.0000 - val_loss: 2.8863e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3819e-07 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9567e-06 - acc: 1.0000 - val_loss: 2.7818e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2896e-06 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8967e-06 - acc: 1.0000 - val_loss: 2.6830e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2219e-06 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8051e-06 - acc: 1.0000 - val_loss: 2.6080e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5623e-07 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7524e-06 - acc: 1.0000 - val_loss: 2.5085e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0035e-07 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6883e-06 - acc: 1.0000 - val_loss: 2.4160e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1351e-07 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6308e-06 - acc: 1.0000 - val_loss: 2.3255e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8231e-07 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5618e-06 - acc: 1.0000 - val_loss: 2.2393e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9860e-07 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4848e-06 - acc: 1.0000 - val_loss: 2.1692e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5251e-07 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4362e-06 - acc: 1.0000 - val_loss: 2.0907e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4271e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3891e-06 - acc: 1.0000 - val_loss: 2.0052e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3150e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3202e-06 - acc: 1.0000 - val_loss: 1.9302e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4936e-07 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2651e-06 - acc: 1.0000 - val_loss: 1.8594e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1548e-07 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2010e-06 - acc: 1.0000 - val_loss: 1.8012e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5821e-07 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1734e-06 - acc: 1.0000 - val_loss: 1.7682e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6427e-07 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1507e-06 - acc: 1.0000 - val_loss: 1.7402e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9290e-07 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1240e-06 - acc: 1.0000 - val_loss: 1.7143e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8386e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1134e-06 - acc: 1.0000 - val_loss: 1.6785e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1288e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0810e-06 - acc: 1.0000 - val_loss: 1.6512e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1921e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0688e-06 - acc: 1.0000 - val_loss: 1.6182e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8237e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0510e-06 - acc: 1.0000 - val_loss: 1.5888e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1584e-07 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0299e-06 - acc: 1.0000 - val_loss: 1.5649e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3320e-06 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0137e-06 - acc: 1.0000 - val_loss: 1.5418e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2165e-06 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9583e-07 - acc: 1.0000 - val_loss: 1.5201e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0606e-07 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.7637e-07 - acc: 1.0000 - val_loss: 1.5033e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6822e-07 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.6421e-07 - acc: 1.0000 - val_loss: 1.4857e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1474e-06 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.5448e-07 - acc: 1.0000 - val_loss: 1.4640e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8231e-07 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3501e-07 - acc: 1.0000 - val_loss: 1.4465e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5448e-07 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2123e-07 - acc: 1.0000 - val_loss: 1.4289e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2240e-06 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.1312e-07 - acc: 1.0000 - val_loss: 1.4107e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1474e-06 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9690e-07 - acc: 1.0000 - val_loss: 1.3953e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4752e-06 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8879e-07 - acc: 1.0000 - val_loss: 1.3792e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0580e-06 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.7257e-07 - acc: 1.0000 - val_loss: 1.3665e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3015e-07 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6527e-07 - acc: 1.0000 - val_loss: 1.3518e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9115e-07 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5068e-07 - acc: 1.0000 - val_loss: 1.3385e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0978e-07 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4176e-07 - acc: 1.0000 - val_loss: 1.3266e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8685e-07 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3040e-07 - acc: 1.0000 - val_loss: 1.3147e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6939e-07 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2229e-07 - acc: 1.0000 - val_loss: 1.3027e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5938e-07 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1418e-07 - acc: 1.0000 - val_loss: 1.2866e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4529e-07 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9878e-07 - acc: 1.0000 - val_loss: 1.2740e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7173e-06 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9229e-07 - acc: 1.0000 - val_loss: 1.2593e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0233e-07 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8012e-07 - acc: 1.0000 - val_loss: 1.2467e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9174e-07 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7445e-07 - acc: 1.0000 - val_loss: 1.2340e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8056e-07 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6310e-07 - acc: 1.0000 - val_loss: 1.2235e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9663e-07 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5661e-07 - acc: 1.0000 - val_loss: 1.2144e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5758e-06 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.4688e-07 - acc: 1.0000 - val_loss: 1.2004e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0781e-08 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3796e-07 - acc: 1.0000 - val_loss: 1.1906e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6741e-07 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3309e-07 - acc: 1.0000 - val_loss: 1.1801e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9977e-07 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2255e-07 - acc: 1.0000 - val_loss: 1.1709e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6726e-06 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1606e-07 - acc: 1.0000 - val_loss: 1.1597e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1781e-07 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0795e-07 - acc: 1.0000 - val_loss: 1.1513e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2724e-07 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0228e-07 - acc: 1.0000 - val_loss: 1.1408e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6135e-07 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9660e-07 - acc: 1.0000 - val_loss: 1.1310e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3155e-07 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8930e-07 - acc: 1.0000 - val_loss: 1.1226e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9174e-07 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8362e-07 - acc: 1.0000 - val_loss: 1.1128e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4007e-06 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7795e-07 - acc: 1.0000 - val_loss: 1.1029e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2841e-07 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7065e-07 - acc: 1.0000 - val_loss: 1.0952e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1883e-06 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6659e-07 - acc: 1.0000 - val_loss: 1.0854e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8685e-07 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5930e-07 - acc: 1.0000 - val_loss: 1.0777e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3586e-07 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5281e-07 - acc: 1.0000 - val_loss: 1.0693e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3644e-07 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4713e-07 - acc: 1.0000 - val_loss: 1.0616e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7684e-07 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3902e-07 - acc: 1.0000 - val_loss: 1.0546e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2815e-06 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3253e-07 - acc: 1.0000 - val_loss: 1.0468e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3272e-07 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2605e-07 - acc: 1.0000 - val_loss: 1.0398e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4566e-06 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1794e-07 - acc: 1.0000 - val_loss: 1.0363e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 105/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4454e-06 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1550e-07 - acc: 1.0000 - val_loss: 1.0328e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5572e-06 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1307e-07 - acc: 1.0000 - val_loss: 1.0293e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8918e-07 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1145e-07 - acc: 1.0000 - val_loss: 1.0265e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0606e-07 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0902e-07 - acc: 1.0000 - val_loss: 1.0237e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3097e-07 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0334e-07 - acc: 1.0000 - val_loss: 1.0209e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3821e-06 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0091e-07 - acc: 1.0000 - val_loss: 1.0167e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3858e-06 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9929e-07 - acc: 1.0000 - val_loss: 1.0125e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3821e-06 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9604e-07 - acc: 1.0000 - val_loss: 1.0090e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1548e-06 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9442e-07 - acc: 1.0000 - val_loss: 1.0048e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3958e-07 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8793e-07 - acc: 1.0000 - val_loss: 1.0027e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8743e-07 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8712e-07 - acc: 1.0000 - val_loss: 9.9847e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6450e-07 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8469e-07 - acc: 1.0000 - val_loss: 9.9567e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3448e-06 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8307e-07 - acc: 1.0000 - val_loss: 9.9216e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2517e-06 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7739e-07 - acc: 1.0000 - val_loss: 9.8866e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1325e-06 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7334e-07 - acc: 1.0000 - val_loss: 9.8515e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3155e-07 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7171e-07 - acc: 1.0000 - val_loss: 9.8235e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6566e-07 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6847e-07 - acc: 1.0000 - val_loss: 9.7954e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7509e-07 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6766e-07 - acc: 1.0000 - val_loss: 9.7604e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2782e-07 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6360e-07 - acc: 1.0000 - val_loss: 9.7253e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0547e-07 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6198e-07 - acc: 1.0000 - val_loss: 9.6902e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7742e-07 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5955e-07 - acc: 1.0000 - val_loss: 9.6622e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3001e-06 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5631e-07 - acc: 1.0000 - val_loss: 9.6271e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5332e-07 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5225e-07 - acc: 1.0000 - val_loss: 9.5991e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2154e-07 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4982e-07 - acc: 1.0000 - val_loss: 9.5640e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0175e-07 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4901e-07 - acc: 1.0000 - val_loss: 9.5290e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4156e-07 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4658e-07 - acc: 1.0000 - val_loss: 9.5009e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3001e-06 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4090e-07 - acc: 1.0000 - val_loss: 9.4589e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0175e-07 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3847e-07 - acc: 1.0000 - val_loss: 9.4308e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3528e-07 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3441e-07 - acc: 1.0000 - val_loss: 9.3958e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4587e-07 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3360e-07 - acc: 1.0000 - val_loss: 9.3607e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1979e-07 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3279e-07 - acc: 1.0000 - val_loss: 9.3327e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0233e-07 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3036e-07 - acc: 1.0000 - val_loss: 9.3046e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6194e-07 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2630e-07 - acc: 1.0000 - val_loss: 9.2696e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7601e-07 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2549e-07 - acc: 1.0000 - val_loss: 9.2415e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2037e-07 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2144e-07 - acc: 1.0000 - val_loss: 9.2135e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5018e-07 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1738e-07 - acc: 1.0000 - val_loss: 9.1854e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9546e-07 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1414e-07 - acc: 1.0000 - val_loss: 9.1644e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5763e-07 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1333e-07 - acc: 1.0000 - val_loss: 9.1364e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5274e-07 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1089e-07 - acc: 1.0000 - val_loss: 9.1083e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4587e-07 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0603e-07 - acc: 1.0000 - val_loss: 9.0803e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4273e-07 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0441e-07 - acc: 1.0000 - val_loss: 9.0452e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6857e-08 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0278e-07 - acc: 1.0000 - val_loss: 9.0242e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6508e-07 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9954e-07 - acc: 1.0000 - val_loss: 8.9961e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1234e-07 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9873e-07 - acc: 1.0000 - val_loss: 8.9681e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0291e-07 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9711e-07 - acc: 1.0000 - val_loss: 8.9470e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3709e-06 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9467e-07 - acc: 1.0000 - val_loss: 8.9120e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6822e-07 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9143e-07 - acc: 1.0000 - val_loss: 8.8839e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3842e-07 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8900e-07 - acc: 1.0000 - val_loss: 8.8489e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8312e-07 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8657e-07 - acc: 1.0000 - val_loss: 8.8208e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0547e-07 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8413e-07 - acc: 1.0000 - val_loss: 8.8068e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 155/200\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 5.1781e-07 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.8170e-07 - acc: 1.0000 - val_loss: 8.7928e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 156/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2852e-06 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8008e-07 - acc: 1.0000 - val_loss: 8.7788e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 157/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4214e-07 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7927e-07 - acc: 1.0000 - val_loss: 8.7648e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 158/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9407e-08 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7846e-07 - acc: 1.0000 - val_loss: 8.7507e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 159/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7567e-07 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7846e-07 - acc: 1.0000 - val_loss: 8.7367e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 160/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0393e-06 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7683e-07 - acc: 1.0000 - val_loss: 8.7227e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 161/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5134e-07 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7521e-07 - acc: 1.0000 - val_loss: 8.7087e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 162/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3469e-07 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7359e-07 - acc: 1.0000 - val_loss: 8.7017e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 163/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7278e-07 - acc: 1.0000 - val_loss: 8.6806e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 164/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1623e-06 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7035e-07 - acc: 1.0000 - val_loss: 8.6666e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 165/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0058e-07 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6872e-07 - acc: 1.0000 - val_loss: 8.6526e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0175e-07 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.6548e-07 - acc: 1.0000 - val_loss: 8.6386e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4587e-07 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6548e-07 - acc: 1.0000 - val_loss: 8.6245e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1697e-06 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6386e-07 - acc: 1.0000 - val_loss: 8.6105e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1956e-08 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6143e-07 - acc: 1.0000 - val_loss: 8.5965e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6391e-07 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5899e-07 - acc: 1.0000 - val_loss: 8.5825e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1586e-06 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5818e-07 - acc: 1.0000 - val_loss: 8.5684e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1027e-06 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5575e-07 - acc: 1.0000 - val_loss: 8.5544e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7229e-07 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5413e-07 - acc: 1.0000 - val_loss: 8.5404e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4214e-07 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5413e-07 - acc: 1.0000 - val_loss: 8.5334e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7998e-07 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5332e-07 - acc: 1.0000 - val_loss: 8.5194e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3272e-07 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5332e-07 - acc: 1.0000 - val_loss: 8.5053e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0920e-07 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.5007e-07 - acc: 1.0000 - val_loss: 8.4843e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0393e-06 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4845e-07 - acc: 1.0000 - val_loss: 8.4703e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5332e-07 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.4845e-07 - acc: 1.0000 - val_loss: 8.4563e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2759e-07 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4602e-07 - acc: 1.0000 - val_loss: 8.4422e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1723e-07 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4521e-07 - acc: 1.0000 - val_loss: 8.4282e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0542e-06 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4521e-07 - acc: 1.0000 - val_loss: 8.4072e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0489e-07 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4440e-07 - acc: 1.0000 - val_loss: 8.3932e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8370e-07 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4359e-07 - acc: 1.0000 - val_loss: 8.3791e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3842e-07 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4034e-07 - acc: 1.0000 - val_loss: 8.3651e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0654e-06 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4034e-07 - acc: 1.0000 - val_loss: 8.3511e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5763e-07 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3953e-07 - acc: 1.0000 - val_loss: 8.3371e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3900e-07 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.3872e-07 - acc: 1.0000 - val_loss: 8.3160e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8254e-07 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3872e-07 - acc: 1.0000 - val_loss: 8.2950e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1101e-06 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3710e-07 - acc: 1.0000 - val_loss: 8.2740e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6822e-07 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3629e-07 - acc: 1.0000 - val_loss: 8.2599e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0862e-07 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.3304e-07 - acc: 1.0000 - val_loss: 8.2529e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2107e-06 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3304e-07 - acc: 1.0000 - val_loss: 8.2389e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8719e-07 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3223e-07 - acc: 1.0000 - val_loss: 8.2249e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9407e-08 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3061e-07 - acc: 1.0000 - val_loss: 8.2109e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0654e-06 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2899e-07 - acc: 1.0000 - val_loss: 8.1968e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0878e-06 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2818e-07 - acc: 1.0000 - val_loss: 8.1828e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7567e-07 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2656e-07 - acc: 1.0000 - val_loss: 8.1758e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "3/5 [=================>............] - ETA: 0s - loss: 4.9794e-07 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.2493e-07 - acc: 1.0000 - val_loss: 8.1618e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4703e-07 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2493e-07 - acc: 1.0000 - val_loss: 8.1407e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        # save_best_only -> 모델 정확도가 이전보다 향상된 경우에만 모델 저장\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        # 정확도 개선이 없을시 학습률(factor) 0.5배로 감소, 50 에포크 동안 개선 없을 경우 학습률 감소\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 197ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[11,  0],\n",
       "        [ 0,  6]],\n",
       "\n",
       "       [[11,  0],\n",
       "        [ 0,  6]],\n",
       "\n",
       "       [[12,  0],\n",
       "        [ 0,  5]]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# 다중 레이블 혼동 행렬로 모델 평가\n",
    "# [[True Negative, False Positive],\n",
    "# [False Negative, True Positive]]\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
